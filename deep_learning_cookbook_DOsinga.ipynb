{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 3. Word embendings (Word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from keras.utils import get_file\n",
    "import gensim\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(10, 10)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "from collections import Counter\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model should download before using\n",
    "MODEL = './data/GoogleNews-vectors-negative300.bin.gz'\n",
    "\n",
    "unzipped = os.path.join(MODEL)\n",
    "if not os.path.isfile(unzipped):\n",
    "    with open(unzipped, 'wb') as fout:\n",
    "        zcat = subprocess.Popen(['zcat'],\n",
    "                          stdin=open(path),\n",
    "                          stdout=fout\n",
    "                         )\n",
    "        zcat.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(unzipped, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take this model for a spin by looking at what things are most similar to espresso. As expected, coffee like items show up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['espresso'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the famous equation, what is like woman if king is like man? We create a quick method to these calculations here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_is_to_B_as_C_is_to(a, b, c, topn=1):\n",
    "    a, b, c = map(lambda x:x if type(x) == list else [x], (a, b, c))\n",
    "    res = model.most_similar(positive=b + c, negative=a, topn=topn)\n",
    "    if len(res):\n",
    "        if topn == 1:\n",
    "            return res[0][0]\n",
    "        return [x[0] for x in res]\n",
    "    return None\n",
    "\n",
    "A_is_to_B_as_C_is_to('man', 'woman', 'king')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this equation to acurately predict the capitals of countries by looking at what has the same relationship as Berlin has to Germany for selected countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in 'Italy', 'France', 'India', 'China':\n",
    "    print('%s is the capital of %s' % \n",
    "          (A_is_to_B_as_C_is_to('Germany', 'Berlin', country), country))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can do the same for important products for given companies. Here we seed the products equation with two products, the iPhone for Apple and Starbucks_coffee for Starbucks. Note that numbers are replaced by # in the embedding model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in 'Google', 'IBM', 'Boeing', 'Microsoft', 'Samsung':\n",
    "    products = A_is_to_B_as_C_is_to(\n",
    "        ['Starbucks', 'Apple'], \n",
    "        ['Starbucks_coffee', 'iPhone'], \n",
    "        company, topn=3)\n",
    "    print('%s -> %s' % \n",
    "          (company, ', '.join(products)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some clustering by picking three categories of items, drinks, countries and sports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beverages = ['espresso', 'beer', 'vodka', 'wine', 'cola', 'tea']\n",
    "countries = ['Italy', 'Germany', 'Russia', 'France', 'USA', 'India']\n",
    "sports = ['soccer', 'handball', 'hockey', 'cycling', 'basketball', 'cricket']\n",
    "\n",
    "items = beverages + countries + sports\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vectors = [(item, model[item]) \n",
    "                    for item in items\n",
    "                    if item in model]\n",
    "len(item_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use TSNE for clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.asarray([x[1] for x in item_vectors])\n",
    "lengths = np.linalg.norm(vectors, axis=1)\n",
    "norm_vectors = (vectors.T / lengths).T\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=10, verbose=2).fit_transform(norm_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And matplotlib to show the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tsne[:,0]\n",
    "y=tsne[:,1]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "\n",
    "for item, x1, y1 in zip(item_vectors, x, y):\n",
    "    ax.annotate(item[0], (x1, y1), size=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the countries, sports and drinks all form their own little clusters, with arguably cricket and India attracting each other and maybe less clear, wine and France and Italy and espresso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding entity classes in embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#figsize(12, 8)\n",
    "\n",
    "from sklearn import svm\n",
    "from keras.utils import get_file\n",
    "import os\n",
    "import gensim\n",
    "import numpy as np\n",
    "import random\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from IPython.core.pylabtools import figsize\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most similar to a bunch of countries are some other countries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(unzipped, binary=True)\n",
    "model.most_similar(positive=['Germany'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['Annita_Kirsten'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we'll create a training set with countries and non countries and get a support vector machine to learn the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = list(csv.DictReader(open('data/countries.csv')))\n",
    "countries[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = [x['name'] for x in random.sample(countries, 40)]\n",
    "negative = random.sample(model.vocab.keys(), 5000)\n",
    "negative[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled = [(p, 1) for p in positive] + [(n, 0) for n in negative]\n",
    "random.shuffle(labelled)\n",
    "X = np.asarray([model[w] for w, l in labelled])\n",
    "y = np.asarray([l for w, l in labelled])\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_FRACTION = 0.3\n",
    "cut_off = int(TRAINING_FRACTION * len(labelled))\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X[:cut_off], y[:cut_off]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did alright, 99.9% precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = clf.predict(X[cut_off:])\n",
    "\n",
    "missed = [country for (pred, truth, country) in \n",
    " zip(res, y[cut_off:], labelled[cut_off:]) if pred != truth]\n",
    "\n",
    "100 - 100 * float(len(missed)) / len(res), missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = clf.predict(model.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for word, pred in zip(model.index2word, all_predictions):\n",
    "    if pred:\n",
    "        res.append(word)\n",
    "        if len(res) == 150:\n",
    "            break\n",
    "random.sample(res, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_to_idx = {country['name']: idx for idx, country in enumerate(countries)}\n",
    "country_vecs = np.asarray([model[c['name']] for c in countries])\n",
    "country_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check to see what is similar to Canada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = np.dot(country_vecs, country_vecs[country_to_idx['Canada']])\n",
    "for idx in reversed(np.argsort(dists)[-10:]):\n",
    "    print(countries[idx]['name'], dists[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking countries for a specific term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_countries(term, topn=10, field='name'):\n",
    "    if not term in model:\n",
    "        return []\n",
    "    vec = model[term]\n",
    "    dists = np.dot(country_vecs, vec)\n",
    "    return [(countries[idx][field], float(dists[idx])) \n",
    "            for idx in reversed(np.argsort(dists)[-topn:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_countries('cricket')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize this on a world map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "world.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot some maps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_term(term):\n",
    "    d = {k.upper(): v for k, v in rank_countries(term, topn=0, field='cc3')}\n",
    "    world[term] = world['iso_a3'].map(d)\n",
    "    world[term] /= world[term].max()\n",
    "    world.dropna().plot(term, cmap='OrRd')\n",
    "\n",
    "map_term('coffee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('cricket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('China')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('vodka')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
