{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eff9ca7",
   "metadata": {},
   "source": [
    "## Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16527b0a",
   "metadata": {},
   "source": [
    "Инициализация интерактвиного сеанса Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f6aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e1964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from version v2.x you should use this for activate version\n",
    "import tensorflow.compat.v1 as tfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df7caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tfc.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06958b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание тензора нулей\n",
    "a = tf.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# возрат значения\n",
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выведение матрицы с единицами\n",
    "b = tf.ones((2, 2, 2))\n",
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a2121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполнение тензоров произвольными значениями\n",
    "c = tf.fill((2, 2), value=5.)\n",
    "c.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание константных тензоров (не должны изменяться во время выполнения программ)\n",
    "a = tf.constant(3)\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7993ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# отбор случайных значений для тензора из нормального распределения\n",
    "b = tf.random.normal((2, 2), mean=0, stddev=1)\n",
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840f742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# отбор случайных значений для тензора из равномерного распределения\n",
    "a = tf.random.uniform((2, 2), minval=-2, maxval=2)\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e30dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сложение тензоров\n",
    "c = tf.ones((2, 2))\n",
    "d = tf.ones((2, 2))\n",
    "e = c + d\n",
    "e.numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a018b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 2 * e\n",
    "f.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c56a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# поэлементное умножение (при умножении тензоров мы получаем не матричное умножение, а поэлементное)\n",
    "c = tf.fill((2, 2), 2.)\n",
    "d = tf.fill((2, 2), 7.)\n",
    "e = c * d\n",
    "e.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650884d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание единичной матрицы - это квадратная матрица, элементы которой равны 0 везде, кроме главной диагонали, где они равны 1\n",
    "tf.eye(4).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0475e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.range(начало, граница(не включительно), дельта)\n",
    "r = tf.range(1, 5, 1)\n",
    "r.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cedc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# диагональная матрица - так же являются ненулевыми по диагонали, но по диагонали могут быть произвольные значения\n",
    "d = tf.linalg.diag(r)\n",
    "d.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d74123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение транспонированной матрицы\n",
    "a = tf.ones((2, 3))\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6969740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "at = tf.transpose(a)\n",
    "at.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9e8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выполнение матричного умножения\n",
    "b = tf.ones((3, 4))\n",
    "c = tf.matmul(a, b)\n",
    "c.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# смена типа данных тензора\n",
    "a = tf.ones((2, 2), dtype=tf.int32)\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1f1e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.cast(a, tf.float32)\n",
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb01124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# манипуляция с формами тензоров. reshape - позволяет конвертировать тензоры в тензоры другой формы\n",
    "a = tf.ones(8)\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b77bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.reshape(a, (4, 2))\n",
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49228fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.reshape(a, (2, 2, 2))\n",
    "c.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4cdffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение формы тензора\n",
    "a = tf.ones(2)\n",
    "a.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e57b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand_dims добавляет в тензор новую размерность размера 1 \n",
    "b = tf.expand_dims(a, 0)\n",
    "b.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e23dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.expand_dims(a, 1)\n",
    "c.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f92b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeeze удаляет из тензора все размерности размера 1, превращая например векторк-строку 2 ранга в вектор 1-го ранга\n",
    "d = tf.squeeze(b)\n",
    "d.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d46789",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbc1633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# примеры транслирования - добавления к матрицам тензорной системы вектора разного размера\n",
    "a = tf.ones((2, 2))\n",
    "b = tf.range(0, 2, 1, dtype=tf.float32) \n",
    "# если не задать явно тип, то будет ошибка, т.к. tensorflow не выполняет неявное приведение типов\n",
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a + b\n",
    "c.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a293c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow выполняет только декларативное сложение\n",
    "a = tf.constant(3)\n",
    "b = tf.constant(4)\n",
    "c = a + b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7655c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обработка сеансов явным образом\n",
    "tf.compat.v1.disable_eager_execution() # need to disable eager in TF2.x\n",
    "sess = tfc.Session()\n",
    "a = tf.ones((2, 2))\n",
    "b = tf.matmul(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c4e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bcd2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# объекты-переменные Variable служат контейнером для тензоров\n",
    "a = tf.Variable(tf.ones((2, 2)))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a047abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.global_variables_initializer() - инициализирует все переменные для расчета. более не используется\n",
    "init_op = tf.local_variables_initializer()\n",
    "sess.run(init_op)\n",
    "print(sess.run(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e84a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# при помощи функции assign мы можем обновить значение существующей переменной\n",
    "tf.compat.v1.disable_eager_execution() # need to disable eager in TF2.x\n",
    "sess = tfc.Session()\n",
    "sess.run(a.assign(tf.zeros((2, 2))))\n",
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676b5882",
   "metadata": {},
   "source": [
    "## Chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b9f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# игрушечный набор регрессионных данных\n",
    "import numpy as np\n",
    "np.random.seed(456)\n",
    "import  tensorflow as tf\n",
    "tf.random.set_seed(456)\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23767f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7bf645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции ошибок\n",
    "def pearson_r2_score(y, y_pred):\n",
    " # \"\"\"Computes Pearson R^2 (square of Pearson correlation).\"\"\"\n",
    "  return pearsonr(y, y_pred)[0]**2\n",
    "\n",
    "def rms_score(y_true, y_pred):\n",
    "# \"\"\"Computes RMS error.\"\"\"\n",
    "  return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1204a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "N = 3\n",
    "#N = 100\n",
    "w_true = 5\n",
    "b_true = 2\n",
    "noise_scale = .1\n",
    "x_np = np.random.rand(N, 1)\n",
    "noise = np.random.normal(scale=noise_scale, size=(N, 1))\n",
    "# Convert shape of y_np to (N,)\n",
    "y_np = np.reshape(w_true * x_np  + b_true + noise, (-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b894fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save image of the data distribution\n",
    "plt.scatter(x_np, y_np);\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlim(0, 1)\n",
    "plt.title(\"Toy Linear Regression Data, $y = 5x + 2 + N(0, 1)$\")\n",
    "plt.savefig(\"lr_data.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df97c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# тренировка линейной регрессионной модели\n",
    "# Generate tensorflow graph\n",
    "# placeholders - (заполнитель) это способ ввода информации в вычислительный граф\n",
    "\n",
    "import tensorflow.compat.v1 as tfc\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.name_scope('placeholders'):\n",
    "        x = tfc.placeholder(tf.float32, (3, 1))\n",
    "        y = tfc.placeholder(tf.float32, (3, ))\n",
    "# name_scope (область имен) - представляет собой механизм определения областей видимости для управления коллекциями переменных\n",
    "# обратите внимание, что x - это скаляр, поэтому W - это одиночный заучиваемый вес\n",
    "    with tf.name_scope('weights'):\n",
    "        W = tf.Variable(tfc.random_normal((1, 1)))\n",
    "        b = tf.Variable(tfc.random_normal((1,)))\n",
    "    with tf.name_scope('prediction'):\n",
    "        y_pred = tf.matmul(x,W) + b\n",
    "    with tf.name_scope('loss'):\n",
    "        l = tf.reduce_sum((y-y_pred)**2)\n",
    "    #Добавить оптимизацию тренировки\n",
    "    with tf.name_scope('optim'):\n",
    "        #Задать скорость заучивания .001, как рекомендовано выше.\n",
    "        train_op = tfc.train.AdamOptimizer(.001).minimize(l)\n",
    "    with tf.name_scope('summaries'):\n",
    "        #Запись сводки о переменных(скалярных величинах) в заданный каталог журналов\n",
    "        # добавление сводного отчета для функции потерь\n",
    "        tfc.summary.scalar('loss', l)\n",
    "        #Объединение нескольких сводок в одну\n",
    "        merged = tfc.summary.merge_all()\n",
    "\n",
    "    train_writer = tfc.summary.FileWriter('/tmp/lr-train', graph)\n",
    "\n",
    "    n_steps = 8000\n",
    "\n",
    "    with tfc.Session() as sess:\n",
    "        sess.run(tfc.global_variables_initializer())\n",
    "        \n",
    "        #Натренировать модель\n",
    "        for i in range(n_steps):\n",
    "            feed_dict1 = {x: [[1.], [2.], [3.]], y: [2., 3., 4.]}\n",
    "            _, summary, loss = sess.run([train_op, merged, l], feed_dict=feed_dict1)\n",
    "            train_writer.add_summary(summary, i)\n",
    "\n",
    "            # print epoch and loss\n",
    "            if i % 100 == 0:\n",
    "                print(f'Epoch: {i}'.ljust(13) + f'loss: {loss:.4f}'.ljust(16))\n",
    "            \n",
    "              # Get weights\n",
    "            w_final, b_final = sess.run([W, b])\n",
    "\n",
    "              # Make Predictions\n",
    "            y_pred_np = sess.run(y_pred, feed_dict=feed_dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a46966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_np = np.reshape(y_pred_np, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# квадратичный коэффициент корреляции Пирсона  - это мера корреляции между двумя переменными, которая принимает значение от +1 до 0\n",
    "# при этом +1 указывает на идеальную корреляцию, а 0 - на отсутствие корреляции\n",
    "y_pred_np = np.reshape(y_pred_np, -1)\n",
    "r2 = pearson_r2_score(y_np, y_pred_np)\n",
    "print(\"Pearson R^2: %f\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fb0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE - является мерой усредненной разницы между предсказанными значениями и истинными\n",
    "rms = rms_score(y_np, y_pred_np)\n",
    "print(\"RMS: %f\" % rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35539b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clear figure\n",
    "plt.clf()\n",
    "plt.xlabel(\"Y-true\")\n",
    "plt.ylabel(\"Y-pred\")\n",
    "plt.title(\"Predicted versus True values \"\n",
    "          r\"(Pearson $R^2$: $0.994$)\")\n",
    "plt.scatter(y_np, y_pred_np)\n",
    "plt.savefig(\"lr_pred.png\")\n",
    "\n",
    "# Now draw with learned regression line\n",
    "plt.clf()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"True Model versus Learned Model \"\n",
    "          r\"(RMS: $1.027620$)\")\n",
    "plt.xlim(0, 1)\n",
    "plt.scatter(x_np, y_np)\n",
    "x_left = 0\n",
    "y_left = w_final[0]*x_left + b_final\n",
    "x_right = 1\n",
    "y_right = w_final[0]*x_right + b_final\n",
    "plt.plot([x_left, x_right], [y_left, y_right], color='k')\n",
    "plt.savefig(\"lr_learned.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56749bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример логистической регрессии\n",
    "import numpy as np\n",
    "np.random.seed(456)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(456)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.special import logit\n",
    "\n",
    "# Generate synthetic data\n",
    "N = 100\n",
    "# Zeros form a Gaussian centered at (-1, -1)\n",
    "x_zeros = np.random.multivariate_normal(\n",
    "    mean=np.array((-1, -1)), cov=.1*np.eye(2), size=(N//2,))\n",
    "y_zeros = np.zeros((N//2,))\n",
    "# Ones form a Gaussian centered at (1, 1)\n",
    "x_ones = np.random.multivariate_normal(\n",
    "    mean=np.array((1, 1)), cov=.1*np.eye(2), size=(N//2,))\n",
    "y_ones = np.ones((N//2,))\n",
    "\n",
    "x_np = np.vstack([x_zeros, x_ones])\n",
    "y_np = np.concatenate([y_zeros, y_ones])\n",
    "\n",
    "# Save image of the data distribution\n",
    "plt.xlabel(r\"$x_1$\")\n",
    "plt.ylabel(r\"$x_2$\")\n",
    "plt.title(\"Toy Logistic Regression Data\")\n",
    "\n",
    "# Plot Zeros\n",
    "plt.scatter(x_zeros[:, 0], x_zeros[:, 1], color=\"blue\")\n",
    "plt.scatter(x_ones[:, 0], x_ones[:, 1], color=\"red\")\n",
    "plt.savefig(\"logistic_data.png\")\n",
    "\n",
    "# Generate tensorflow graph\n",
    "with tf.name_scope(\"placeholders\"):\n",
    "  x = tf.placeholder(tf.float32, (N, 2))\n",
    "  y = tf.placeholder(tf.float32, (N,))\n",
    "with tf.name_scope(\"weights\"):\n",
    "  W = tf.Variable(tf.random_normal((2, 1)))\n",
    "  b = tf.Variable(tf.random_normal((1,)))\n",
    "with tf.name_scope(\"prediction\"):\n",
    "  y_logit = tf.squeeze(tf.matmul(x, W) + b)\n",
    "  # the sigmoid gives the class probability of 1\n",
    "  y_one_prob = tf.sigmoid(y_logit)\n",
    "  # Rounding P(y=1) will give the correct prediction.\n",
    "  y_pred = tf.round(y_one_prob)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "  # Compute the cross-entropy term for each datapoint\n",
    "  entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=y_logit, labels=y)\n",
    "  # Sum all contributions\n",
    "  l = tf.reduce_sum(entropy)\n",
    "with tf.name_scope(\"optim\"):\n",
    "  train_op = tf.train.AdamOptimizer(.01).minimize(l)\n",
    "\n",
    "with tf.name_scope(\"summaries\"):\n",
    "  tf.summary.scalar(\"loss\", l)\n",
    "  merged = tf.summary.merge_all()\n",
    "\n",
    "train_writer = tf.summary.FileWriter('/tmp/logistic-train', tf.get_default_graph())\n",
    "\n",
    "n_steps = 1000\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  # Train model\n",
    "  for i in range(n_steps):\n",
    "    feed_dict = {x: x_np, y: y_np}\n",
    "    _, summary, loss = sess.run([train_op, merged, l], feed_dict=feed_dict)\n",
    "    print(\"loss: %f\" % loss)\n",
    "    train_writer.add_summary(summary, i)\n",
    "\n",
    "  # Get weights\n",
    "  w_final, b_final = sess.run([W, b])\n",
    "\n",
    "  # Make Predictions\n",
    "  y_pred_np = sess.run(y_pred, feed_dict={x: x_np})\n",
    "\n",
    "score = accuracy_score(y_np, y_pred_np)\n",
    "print(\"Classification Accuracy: %f\" % score)\n",
    "\n",
    "plt.clf()\n",
    "# Save image of the data distribution\n",
    "plt.xlabel(r\"$x_1$\")\n",
    "plt.ylabel(r\"$x_2$\")\n",
    "plt.title(\"Learned Model (Classification Accuracy: 1.00)\")\n",
    "plt.xlim(-2, 2)\n",
    "plt.ylim(-2, 2)\n",
    "\n",
    "# Plot Zeros\n",
    "plt.scatter(x_zeros[:, 0], x_zeros[:, 1], color=\"blue\")\n",
    "plt.scatter(x_ones[:, 0], x_ones[:, 1], color=\"red\")\n",
    "\n",
    "x_left = -2\n",
    "y_left = (1./w_final[1]) * (-b_final + logit(.5) - w_final[0]*x_left)\n",
    "\n",
    "x_right = 2\n",
    "y_right = (1./w_final[1]) * (-b_final + logit(.5) - w_final[0]*x_right)\n",
    "plt.plot([x_left, x_right], [y_left, y_right], color='k')\n",
    "\n",
    "plt.savefig(\"logistic_pred.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421be5c7",
   "metadata": {},
   "source": [
    "## Chapter 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3124da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обработка набора с токсичными данными Tox21 и использования скрытого слоя с отсевом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(456)\n",
    "import  tensorflow as tf\n",
    "tf.set_random_seed(456)\n",
    "import matplotlib.pyplot as plt\n",
    "import deepchem as dc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "_, (train, valid, test), _ = dc.molnet.load_tox21()\n",
    "train_X, train_y, train_w = train.X, train.y, train.w\n",
    "valid_X, valid_y, valid_w = valid.X, valid.y, valid.w\n",
    "test_X, test_y, test_w = test.X, test.y, test.w\n",
    "\n",
    "# Remove extra tasks\n",
    "train_y = train_y[:, 0]\n",
    "valid_y = valid_y[:, 0]\n",
    "test_y = test_y[:, 0]\n",
    "train_w = train_w[:, 0]\n",
    "valid_w = valid_w[:, 0]\n",
    "test_w = test_w[:, 0]\n",
    "\n",
    "\n",
    "# Generate tensorflow graph\n",
    "d = 1024\n",
    "n_hidden = 50\n",
    "learning_rate = .001\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "dropout_prob = 1.0\n",
    "\n",
    "with tf.name_scope(\"placeholders\"):\n",
    "  x = tf.placeholder(tf.float32, (None, d))\n",
    "  y = tf.placeholder(tf.float32, (None,))\n",
    "  keep_prob = tf.placeholder(tf.float32)\n",
    "with tf.name_scope(\"hidden-layer\"):\n",
    "  W = tf.Variable(tf.random_normal((d, n_hidden)))\n",
    "  b = tf.Variable(tf.random_normal((n_hidden,)))\n",
    "  x_hidden = tf.nn.relu(tf.matmul(x, W) + b)\n",
    "  # Apply dropout\n",
    "  x_hidden = tf.nn.dropout(x_hidden, keep_prob)\n",
    "with tf.name_scope(\"output\"):\n",
    "  W = tf.Variable(tf.random_normal((n_hidden, 1)))\n",
    "  b = tf.Variable(tf.random_normal((1,)))\n",
    "  y_logit = tf.matmul(x_hidden, W) + b\n",
    "  # the sigmoid gives the class probability of 1\n",
    "  y_one_prob = tf.sigmoid(y_logit)\n",
    "  # Rounding P(y=1) will give the correct prediction.\n",
    "  y_pred = tf.round(y_one_prob)\n",
    "with tf.name_scope(\"loss\"):\n",
    "  # Compute the cross-entropy term for each datapoint\n",
    "  y_expand = tf.expand_dims(y, 1)\n",
    "  entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=y_logit, labels=y_expand)\n",
    "  # Sum all contributions\n",
    "  l = tf.reduce_sum(entropy)\n",
    "\n",
    "with tf.name_scope(\"optim\"):\n",
    "  train_op = tf.train.AdamOptimizer(learning_rate).minimize(l)\n",
    "\n",
    "with tf.name_scope(\"summaries\"):\n",
    "  tf.summary.scalar(\"loss\", l)\n",
    "  merged = tf.summary.merge_all()\n",
    "\n",
    "train_writer = tf.summary.FileWriter('/tmp/fcnet-tox21-dropout',\n",
    "                                     tf.get_default_graph())\n",
    "N = train_X.shape[0]\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  step = 0\n",
    "  for epoch in range(n_epochs):\n",
    "    pos = 0\n",
    "    while pos < N:\n",
    "      batch_X = train_X[pos:pos+batch_size]\n",
    "      batch_y = train_y[pos:pos+batch_size]\n",
    "      feed_dict = {x: batch_X, y: batch_y, keep_prob: dropout_prob}\n",
    "      _, summary, loss = sess.run([train_op, merged, l], feed_dict=feed_dict)\n",
    "      print(\"epoch %d, step %d, loss: %f\" % (epoch, step, loss))\n",
    "      train_writer.add_summary(summary, step)\n",
    "    \n",
    "      step += 1\n",
    "      pos += batch_size\n",
    "\n",
    "  # Make Predictions (set keep_prob to 1.0 for predictions)\n",
    "  train_y_pred = sess.run(y_pred, feed_dict={x: train_X, keep_prob: 1.0})\n",
    "  valid_y_pred = sess.run(y_pred, feed_dict={x: valid_X, keep_prob: 1.0})\n",
    "  test_y_pred = sess.run(y_pred, feed_dict={x: test_X, keep_prob: 1.0})\n",
    "\n",
    "train_weighted_score = accuracy_score(train_y, train_y_pred, sample_weight=train_w)\n",
    "print(\"Train Weighted Classification Accuracy: %f\" % train_weighted_score)\n",
    "valid_weighted_score = accuracy_score(valid_y, valid_y_pred, sample_weight=valid_w)\n",
    "print(\"Valid Weighted Classification Accuracy: %f\" % valid_weighted_score)\n",
    "test_weighted_score = accuracy_score(test_y, test_y_pred, sample_weight=test_w)\n",
    "print(\"Test Weighted Classification Accuracy: %f\" % test_weighted_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83433b04",
   "metadata": {},
   "source": [
    "## Chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa17f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# определение и тренировка случайного леса на наборе данных Tox21\n",
    "import numpy as np\n",
    "np.random.seed(456)\n",
    "import matplotlib.pyplot as plt\n",
    "import deepchem as dc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "_, (train, valid, test), _ = dc.molnet.load_tox21()\n",
    "train_X, train_y, train_w = train.X, train.y, train.w\n",
    "valid_X, valid_y, valid_w = valid.X, valid.y, valid.w\n",
    "test_X, test_y, test_w = test.X, test.y, test.w\n",
    "\n",
    "# Remove extra tasks\n",
    "train_y = train_y[:, 0]\n",
    "valid_y = valid_y[:, 0]\n",
    "test_y = test_y[:, 0]\n",
    "train_w = train_w[:, 0]\n",
    "valid_w = valid_w[:, 0]\n",
    "test_w = test_w[:, 0]\n",
    "\n",
    "# Generate tensorflow graph\n",
    "sklearn_model = RandomForestClassifier(\n",
    "    class_weight=\"balanced\", n_estimators=50)\n",
    "print(\"About to fit model on train set.\")\n",
    "sklearn_model.fit(train_X, train_y)\n",
    "\n",
    "train_y_pred = sklearn_model.predict(train_X)\n",
    "valid_y_pred = sklearn_model.predict(valid_X)\n",
    "test_y_pred = sklearn_model.predict(test_X)\n",
    "\n",
    "weighted_score = accuracy_score(train_y, train_y_pred, sample_weight=train_w)\n",
    "print(\"Weighted train Classification Accuracy: %f\" % weighted_score)\n",
    "weighted_score = accuracy_score(valid_y, valid_y_pred, sample_weight=valid_w)\n",
    "print(\"Weighted valid Classification Accuracy: %f\" % weighted_score)\n",
    "weighted_score = accuracy_score(test_y, test_y_pred, sample_weight=test_w)\n",
    "print(\"Weighted test Classification Accuracy: %f\" % weighted_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ef536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# использование полносвязных сетей с гиперпараметрами \n",
    "import numpy as np\n",
    "np.random.seed(456)\n",
    "import  tensorflow as tf\n",
    "tf.set_random_seed(456)\n",
    "import matplotlib.pyplot as plt\n",
    "import deepchem as dc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def eval_tox21_hyperparams(n_hidden=50, n_layers=1, learning_rate=.001,\n",
    "                           dropout_prob=0.5, n_epochs=45, batch_size=100,\n",
    "                           weight_positives=True):\n",
    "    \n",
    "# n_hidden - управляет количеством нейронов в каждом скрытом слое сети\n",
    "# n_layers - количество скрытых слоев\n",
    "# learning_rate - контролирует скорость заучивания\n",
    "# dropout_prob - является вероятностью, что нейроны не сброшены во время шагов тренировки\n",
    "# n_epochs - количество проходов по всем данным\n",
    "# batch_size - количество точек данных в каждом пакете\n",
    "# weight_positives - взвешивает прецеденты классов, чтобы они обладали одинаковым весом\n",
    "\n",
    "  print(\"---------------------------------------------\")\n",
    "  print(\"Model hyperparameters\")\n",
    "  print(\"n_hidden = %d\" % n_hidden)\n",
    "  print(\"n_layers = %d\" % n_layers)\n",
    "  print(\"learning_rate = %f\" % learning_rate)\n",
    "  print(\"n_epochs = %d\" % n_epochs)\n",
    "  print(\"batch_size = %d\" % batch_size)\n",
    "  print(\"weight_positives = %s\" % str(weight_positives))\n",
    "  print(\"dropout_prob = %f\" % dropout_prob)\n",
    "  print(\"---------------------------------------------\")\n",
    "\n",
    "  d = 1024\n",
    "  graph = tf.Graph()\n",
    "  with graph.as_default():\n",
    "    _, (train, valid, test), _ = dc.molnet.load_tox21()\n",
    "    train_X, train_y, train_w = train.X, train.y, train.w\n",
    "    valid_X, valid_y, valid_w = valid.X, valid.y, valid.w\n",
    "    test_X, test_y, test_w = test.X, test.y, test.w\n",
    "\n",
    "    # Remove extra tasks\n",
    "    train_y = train_y[:, 0]\n",
    "    valid_y = valid_y[:, 0]\n",
    "    test_y = test_y[:, 0]\n",
    "    train_w = train_w[:, 0]\n",
    "    valid_w = valid_w[:, 0]\n",
    "    test_w = test_w[:, 0]\n",
    "\n",
    "    # Generate tensorflow graph\n",
    "    with tf.name_scope(\"placeholders\"):\n",
    "      x = tf.placeholder(tf.float32, (None, d))\n",
    "      y = tf.placeholder(tf.float32, (None,))\n",
    "      w = tf.placeholder(tf.float32, (None,))\n",
    "      keep_prob = tf.placeholder(tf.float32)\n",
    "    for layer in range(n_layers):\n",
    "      with tf.name_scope(\"layer-%d\" % layer):\n",
    "        W = tf.Variable(tf.random_normal((d, n_hidden)))\n",
    "        b = tf.Variable(tf.random_normal((n_hidden,)))\n",
    "        x_hidden = tf.nn.relu(tf.matmul(x, W) + b)\n",
    "        # Apply dropout\n",
    "        x_hidden = tf.nn.dropout(x_hidden, keep_prob)\n",
    "    with tf.name_scope(\"output\"):\n",
    "      W = tf.Variable(tf.random_normal((n_hidden, 1)))\n",
    "      b = tf.Variable(tf.random_normal((1,)))\n",
    "      y_logit = tf.matmul(x_hidden, W) + b\n",
    "      # the sigmoid gives the class probability of 1\n",
    "      y_one_prob = tf.sigmoid(y_logit)\n",
    "      # Rounding P(y=1) will give the correct prediction.\n",
    "      y_pred = tf.round(y_one_prob)\n",
    "    with tf.name_scope(\"loss\"):\n",
    "      # Compute the cross-entropy term for each datapoint\n",
    "      y_expand = tf.expand_dims(y, 1)\n",
    "      entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=y_logit, labels=y_expand)\n",
    "      # Multiply by weights\n",
    "      if weight_positives:\n",
    "        w_expand = tf.expand_dims(w, 1)\n",
    "        entropy = w_expand * entropy\n",
    "      # Sum all contributions\n",
    "      l = tf.reduce_sum(entropy)\n",
    "\n",
    "    with tf.name_scope(\"optim\"):\n",
    "      train_op = tf.train.AdamOptimizer(learning_rate).minimize(l)\n",
    "\n",
    "    with tf.name_scope(\"summaries\"):\n",
    "      tf.summary.scalar(\"loss\", l)\n",
    "      merged = tf.summary.merge_all()\n",
    "\n",
    "    hyperparam_str = \"d-%d-hidden-%d-lr-%f-n_epochs-%d-batch_size-%d-weight_pos-%s\" % (\n",
    "        d, n_hidden, learning_rate, n_epochs, batch_size, str(weight_positives))\n",
    "    train_writer = tf.summary.FileWriter('/tmp/fcnet-func-' + hyperparam_str,\n",
    "                                         tf.get_default_graph())\n",
    "    N = train_X.shape[0]\n",
    "    with tf.Session() as sess:\n",
    "      sess.run(tf.global_variables_initializer())\n",
    "      step = 0\n",
    "      for epoch in range(n_epochs):\n",
    "        pos = 0\n",
    "        while pos < N:\n",
    "          batch_X = train_X[pos:pos+batch_size]\n",
    "          batch_y = train_y[pos:pos+batch_size]\n",
    "          batch_w = train_w[pos:pos+batch_size]\n",
    "          feed_dict = {x: batch_X, y: batch_y, w: batch_w, keep_prob: dropout_prob}\n",
    "          _, summary, loss = sess.run([train_op, merged, l], feed_dict=feed_dict)\n",
    "          print(\"epoch %d, step %d, loss: %f\" % (epoch, step, loss))\n",
    "          train_writer.add_summary(summary, step)\n",
    "        \n",
    "          step += 1\n",
    "          pos += batch_size\n",
    "\n",
    "      # Make Predictions (set keep_prob to 1.0 for predictions)\n",
    "      valid_y_pred = sess.run(y_pred, feed_dict={x: valid_X, keep_prob: 1.0})\n",
    "\n",
    "    weighted_score = accuracy_score(valid_y, valid_y_pred, sample_weight=valid_w)\n",
    "    print(\"Valid Weighted Classification Accuracy: %f\" % weighted_score)\n",
    "  return weighted_score\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  score = eval_tox21_hyperparams()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2241b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# перебор гиперпараметров через цикл for\n",
    "\n",
    "import numpy as np\n",
    "from fcnet_func import eval_tox21_hyperparams\n",
    "\n",
    "scores = {}\n",
    "n_reps = 3 \n",
    "hidden_sizes = [30, 60]\n",
    "epochs = [15, 30, 45]\n",
    "dropouts = [.5]\n",
    "num_layers = [1, 2]\n",
    "\n",
    "for rep in range(n_reps):\n",
    "  for n_epochs in epochs:\n",
    "    for hidden_size in hidden_sizes:\n",
    "      for dropout in dropouts:\n",
    "        for n_layers in num_layers:\n",
    "          score = eval_tox21_hyperparams(n_hidden=hidden_size, n_epochs=n_epochs,\n",
    "                                         dropout_prob=dropout, n_layers=n_layers)\n",
    "          if (hidden_size, n_epochs, dropout, n_layers) not in scores:\n",
    "            scores[(hidden_size, n_epochs, dropout, n_layers)] = []\n",
    "          scores[(hidden_size, n_epochs, dropout, n_layers)].append(score)\n",
    "print(\"All Scores\")\n",
    "print(scores)\n",
    "\n",
    "avg_scores = {}\n",
    "for params, param_scores in scores.iteritems():\n",
    "  avg_scores[params] = np.mean(np.array(param_scores))\n",
    "print(\"Scores Averaged over %d repetitions\" % n_reps)\n",
    "print(avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5e451d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env01",
   "language": "python",
   "name": "env01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
